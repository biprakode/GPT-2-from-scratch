{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPE Tokenizer Tests"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T13:37:30.433691752Z",
     "start_time": "2026-02-20T13:37:30.383847134Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from tokenizer.bpe import BPETokenizer, get_byte_encoder, get_pairs\n",
    "from tokenizer.trainer import BPE_Trainer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test get_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T13:37:30.491414464Z",
     "start_time": "2026-02-20T13:37:30.434923930Z"
    }
   },
   "source": [
    "assert get_pairs(['h', 'e', 'l', 'l', 'o']) == {('h','e'), ('e','l'), ('l','l'), ('l','o')}\n",
    "assert get_pairs(['a']) == set()  # single char -> no pairs\n",
    "assert get_pairs(['a', 'b']) == {('a', 'b')}\n",
    "print('get_pairs: PASSED')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_pairs: PASSED\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test byte encoder covers all 256 bytes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T13:37:30.550097658Z",
     "start_time": "2026-02-20T13:37:30.492975379Z"
    }
   },
   "source": [
    "enc = get_byte_encoder()\n",
    "assert len(enc) == 256, f'Expected 256 mappings, got {len(enc)}'\n",
    "assert all(0 <= k <= 255 for k in enc.keys()), 'Keys should be bytes 0-255'\n",
    "# all values should be unique printable chars\n",
    "assert len(set(enc.values())) == 256, 'Mapped chars should be unique'\n",
    "print(f'byte_encoder: PASSED (256 unique mappings)')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byte_encoder: PASSED (256 unique mappings)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train BPE on a small corpus"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T13:37:30.611589505Z",
     "start_time": "2026-02-20T13:37:30.552177161Z"
    }
   },
   "source": [
    "corpus = \"the cat sat on the mat. the cat sat on the cat. the mat sat on the mat.\"\n",
    "trainer = BPE_Trainer(num_merges=50)\n",
    "tok = trainer.train(corpus)\n",
    "\n",
    "print(f'Vocab size: {len(tok.vocab)}')\n",
    "print(f'Merges learned: {len(tok.merges)}')\n",
    "print(f'First 10 merges: {tok.merges[:10]}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge 0/50: ('a', 't')\n",
      "Training complete. Vocab size: 268, Merges: 12\n",
      "Vocab size: 268\n",
      "Merges learned: 12\n",
      "First 10 merges: [('a', 't'), ('h', 'e'), ('t', 'he'), ('Ġ', 'the'), ('Ġ', 'c'), ('Ġc', 'at'), ('s', 'at'), ('Ġ', 'sat'), ('Ġ', 'o'), ('Ġo', 'n')]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test encode/decode roundtrip"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T13:37:30.669560075Z",
     "start_time": "2026-02-20T13:37:30.613636922Z"
    }
   },
   "source": [
    "test_strings = [\n",
    "    \"the cat\",\n",
    "    \"cat sat on mat\",\n",
    "    \"the\",\n",
    "]\n",
    "\n",
    "for s in test_strings:\n",
    "    ids = tok.encode(s)\n",
    "    decoded = tok.decode(ids)\n",
    "    print(f'{s!r:25s} -> {ids} -> {decoded!r}')\n",
    "    assert decoded == s, f'Roundtrip failed: {s!r} != {decoded!r}'\n",
    "\n",
    "print('\\nEncode/decode roundtrip: PASSED')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the cat'                 -> [258, 261] -> 'the cat'\n",
      "'cat sat on mat'          -> [66, 256, 263, 265, 267] -> 'cat sat on mat'\n",
      "'the'                     -> [258] -> 'the'\n",
      "\n",
      "Encode/decode roundtrip: PASSED\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test save/load roundtrip"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T13:37:30.731497003Z",
     "start_time": "2026-02-20T13:37:30.671440943Z"
    }
   },
   "source": [
    "import tempfile, os\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    vocab_path = os.path.join(tmpdir, 'vocab.json')\n",
    "    merge_path = os.path.join(tmpdir, 'merges.txt')\n",
    "\n",
    "    trainer.save(tok, vocab_path, merge_path)\n",
    "\n",
    "    # Load into a fresh tokenizer\n",
    "    tok2 = BPETokenizer()\n",
    "    tok2.load_vocab_merges(vocab_path, merge_path)\n",
    "\n",
    "    # Verify same encode output\n",
    "    for s in test_strings:\n",
    "        ids1 = tok.encode(s)\n",
    "        ids2 = tok2.encode(s)\n",
    "        assert ids1 == ids2, f'Mismatch for {s!r}: {ids1} vs {ids2}'\n",
    "\n",
    "print('Save/load roundtrip: PASSED')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save/load roundtrip: PASSED\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test _bpe with no merges (should return characters unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T13:37:30.787734197Z",
     "start_time": "2026-02-20T13:37:30.733486113Z"
    }
   },
   "source": [
    "empty_tok = BPETokenizer()\n",
    "result = empty_tok._bpe('hello')\n",
    "assert result == 'h e l l o', f'Expected space-separated chars, got {result!r}'\n",
    "print(f'_bpe no merges: PASSED ({result!r})')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_bpe no merges: PASSED ('h e l l o')\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
